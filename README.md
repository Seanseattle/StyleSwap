# StyleSwap: Style-Based Generator Empowers Robust Face Swapping (ECCV 2022)

[Zhiliang Xu](https://scholar.google.com/citations?user=93ZNjNgAAAAJ&hl=zh-CN), [Hang Zhou](https://hangz-nju-cuhk.github.io/), [Zhibin Hong](https://scholar.google.com.au/citations?user=9IIxWBsAAAAJ), [Ziwei Liu](https://liuziwei7.github.io/), [Jiaming Liu](https://jmliu88.github.io/), Zhizhi Guo, Junyu Han, Jingtuo Liu, [Errui Ding](https://scholar.google.com/citations?user=1wzEtxcAAAAJ) and [Jingdong Wang](https://jingdongwang2017.github.io/)

---

### [Project](https://hangz-nju-cuhk.github.io/projects/StyleSwap) | [Paper]() | [Demo](https://www.youtube.com/watch?v=bsHhzU8VSLo)

In this work, we introduce a concise and effective framework named **StyleSwap**. Our core idea is to leverage a style-based generator to empower high-fidelity and robust face swapping, thus the generatorâ€™s advantage can be adopted for optimizing identity similarity. We identify that with only minimal modifications, a StyleGAN2 architecture can successfully handle the desired information from both source and target. 

<img src='./misc/StyleSwap.png' width=880>

## Code 
Code will be released soon

## Citation

If you find our work useful, please cite:
```
@inproceedings{xu2022styleswap,
  title = {StyleSwap: Style-Based Generator Empowers Robust Face Swapping},
  author = {Xu, Zhiliang and Zhou, Hang and Hong, Zhibin and Liu, Ziwei and Liu, Jiaming and Guo, Zhizhi and Han, Junyu and Liu, Jingtuo and Ding, Errui and Wang, Jingdong},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year = {2022}
}
```
